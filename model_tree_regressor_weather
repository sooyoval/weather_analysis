# скачаем интересующие значения погоды в спб в период с 19.07.2015 по 19.07.2021
# затем распакуем архив
!wget -O "weather.xls.gz" "http://93.90.217.253/download/files.synop/26/26063.19.07.2016.19.07.2021.1.0.0.ru.utf8.00000000.xls.gz"
!gzip -df "weather.xls.gz"
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
data = pd.read_excel('weather.xls', skiprows=6) 
data.head(5)  
# посмотрим колонки
data.columns
dates = pd.to_datetime(data['Местное время в Санкт-Петербурге'], dayfirst=True) # Создали новую колонку в нужном питоновском формате
# добавляем новую колонку в таблицу
data['dates'] = dates
x = data['dates']
y = data['T']

plt.figure(figsize=(20, 5))
plt.plot(x, y)
# найдем max, mean, min по температурам

data['T'].max(), data['T'].min(), data['T'].mean()
# найдем наиболее часто встречающееся значение с помощью гистограммы 

data['T'].hist()
# считаем квантили: 95 и 5

data['T'].quantile(0.95), data['T'].quantile(0.05)
# для обучения модели выберем данные за последние 5 лет

condition = data['dates'] > "19-07-2017"

# избавляемся от пропущенных значений
data_short = data[condition]
plt.plot(data_short['dates'], data_short['T'])
# генерируем новые факторы для прогнозирования
data['dayofyear'] = data['dates'].dt.dayofyear
data['month'] = data['dates'].dt.month
# выполним приобразование из 0 до 365 дней от 0 до 1, а затем от 0 до 2pi

data['scaled_dayofyear'] = data['dayofyear'] / 365 * 2 * np.pi

plt.plot(data['dates'], data['dayofyear'])
plt.plot(data['dates'], data['scaled_dayofyear'])  # Другой диапазон

# реализуем преобразование в синус и косинус
data['sin_dayofyear'] = np.sin(data['scaled_dayofyear'])
data['cos_dayofyear'] = np.cos(data['scaled_dayofyear'])
plt.figure(figsize=(20, 4))
data['sin_dayofyear'].plot()
data['cos_dayofyear'].plot()

# чистка данных
condition = data['T'].isna()
data[condition]
data = data[data['T'].notna()]
# после того, как завершили генерацию признаков, будем строить модель
# разбиваем наши данные на тренировочную и тестовую выборки

data_train = data[(data['dates'].dt.year > 2016)&(data['dates'].dt.year < 2020 )]
data_test = data[data['dates'].dt.year >= 2020]

plt.figure(figsize=(20, 5))
plt.plot(data_train['dates'], data_train['T'], color='blue', label='Train')
plt.plot(data_test['dates'], data_test['T'], color='green', label='Test')
plt.legend()

# прогноз погоды взависимости от: день в году

data['dayofyear'] = data['dates'].dt.dayofyear

# Заново переразбиваем датасет для изменений

data_train = data[(data['dates'].dt.year > 2016)&(data['dates'].dt.year < 2020 )]
data_test = data[data['dates'].dt.year >= 2020]

X_train = pd.DataFrame(data_train['dayofyear'])   
y_train = data_train['T']

X_test = pd.DataFrame(data_test['dayofyear'])  
y_test = data_test['T']

# теперь выберем модель 


from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor() 

model.fit(X_train, y_train)

pred_train = model.predict(X_train)
pred_test = model.predict(X_test)

plt.figure(figsize=(20, 5))
plt.plot(data_train['dates'], data_train['T'], color='blue', label='Train', alpha=0.6)
plt.plot(data_test['dates'], data_test['T'], color='green', label='Test', alpha=0.6)

plt.plot(data_train['dates'], pred_train, color='orange', label='Train predict')
plt.plot(data_test['dates'], pred_test, color='red', label='Test predict')
plt.legend()
# расчет ошибки
from sklearn.metrics import mean_squared_error

# чем меньше будет значение тем лучше

print('Train error:', mean_squared_error(y_train, pred_train))  
print('Test error:', mean_squared_error(y_test, pred_test))

